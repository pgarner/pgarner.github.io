---
title: Audio Inference
layout: page
---

Bayesian inference and learning applied to audio, speech and language.

# Vision

We work in the general area of audio processing, but particularly when the audio signal contains speech.  Our capabilities are centred around building models of production and perception that allow machines to mimic the capabilities of humans.  Our models connect the audio signal with higher level semantics such as speech, language, affect and intent.

We embrace rigorous mathematical and Bayesian techniques to infer model parameters as well as the semantics required by the application.  More speculatively, we also use such techniques to allow our models to make inference about the human production, perception and cognitive systems on which they are based.

The group title abbreviates to AI, emphasising a deep connection to the wider Artificial Intelligence field of our host institute.  By the audio and speech focus we contribute to Idiap's core [Human-AI Teaming](https://www.idiap.ch/en/scientific-research/human-ai-teaming) program; by the inference of biological function we aim to also contribute to the [AI for Life](https://www.idiap.ch/en/scientific-research/ai-for-life) program.  In each case we benefit from colleagues with complementary skills, and hope to assist them in their own endeavours.

# People

The team currently includes

* [Alexandre Bittar](https://www.idiap.ch/~abittar/)
* [Louise Coppieters](https://www.idiap.ch/~lcoppieters/)
* [Haolin Chen](https://www.idiap.ch/~hchen/)
* [Mutian He](https://www.idiap.ch/~mhe/)
* [Amina Rufai](https://www.idiap.ch/~arufai/)

At least for the time being we are gender balanced.
