---
title: Projects
layout: page
---

Including collaborations and alumni.  All my SNSF funded projects are on the [SNSF Data Portal](https://data.snf.ch/grants/person/547153) pages.

# Current projects

## [SteADI](https://data.snf.ch/grants/grant/197479)

Storytelling and first impressions in face-to-face and algorithm-powered digital interviews is a collaboration with [Adrian Bangerter](https://www.unine.ch/ipto/home/collaborateurstrices/adrian-bangerter.html) at UniNe and [Marianne Schmid Mast](https://hec.unil.ch/people/mschmidmast) at UNIL.  We will try to automatically extract the information that the psychologists find to be indicative of job performance from interviews.  The project funds [Mutian He](https://www.idiap.ch/~mhe/) and the best parts of [Daniel Carron](https://www.idiap.ch/~dcarron/).

## [NCCR Evolving Language](https://evolvinglanguage.ch/)

I work with [James Henderson](https://www.idiap.ch/~jhenderson/) and [Hervé Bourlard](https://people.idiap.ch/bourlard) in "Low Level Mechanisms of Language Evolution".  We hope to model the junction of the human cochlea and the neural system and uncover the means by which the human auditory system can adapt to changing environments.  It funds [Louise](https://www.idiap.ch/~lcoppieters/)

## [NATAI](https://data.snf.ch/grants/grant/191634)

The Nature of Artificial Intelligence is an [Agora](http://www.snf.ch/en/funding/science-communication/agora/Pages/default.aspx) project; with several Idiap colleagues, we will try to demonstrate speech synthesis in a museum context.  The exhibition is now open at the [Musée de la Main](https://museedelamain.ch/).

## [NAST](https://data.snf.ch/grants/grant/185010)

Neural Architectures for Speech Technology is a follow up to MASS in which we will generalise that work to generic neural architectures.  We aim to embed physiologically and statistically plausible components into standard deep learning architectures to bring them closer to true analogues of biological systems.  It funds [Alex](https://www.idiap.ch/~abittar/) and [Haolin](https://www.idiap.ch/~hchen/).

# Previous projects

## ADeL

ADeL can be thought of as building on the work done in DeepCharisma, bringing in audio visual modes to investigate how speech and gesture processing can help infer charismatic qualities.  The work was funded by [E4S](https://e4s.center/); it was a collaboration with [Daniel Gatica](https://www.idiap.ch/~gatica/) here at Idiap, with [Marianne Schmid Mast](https://hec.unil.ch/people/mschmidmast) and [John Antonakis](http://hec.unil.ch/people/jantonakis) at UNIL and [Jennifer Jordan](https://www.imd.org/faculty/professors/jennifer-jordan/) and [Alyson Meister](https://www.imd.org/faculty/professors/alyson-meister/) at IMD.


## DAHL

DAHL was a collaboration with Swisscom in which Abbas Khosravani and I evaluated state of the art in ASR for Swisscom's particular requirements.  We were particularly interested in word-fragment-based methods and how robust they can be to the "orthographic ambiguity" of Swiss German.

## SHAPED

With [Petr Motlicek](https://www.idiap.ch/~pmotlic) and Logitech, we aimed to bring speech to consumer grade embedded systems.  Working with [Niccolò](https://nantonel.github.io/) and [Vincent](https://www.idiap.ch/~vpollet/).

## [MASS](https://data.snf.ch/grants/grant/165545)

Multilingual Affective Speech Synthesis continued the work begun in SIWIS and SP2 by attempting to model the prosody of emotion.  It funded [Bastian](https://www.idiap.ch/~bschnell/).


## DeepCharisma

Working with Olivier Bornet, John Antonakis and Dominic Rohner, we tried to
infer charisma using deep learning.

## [SUMMA](http://www.summa-project.eu/)

SUMMA was an H2020 funded project on big data and multilingual speech processing.

## Swisscom

With Alexandros Lazaridis, before he moved to Swisscom.

## [SP2](https://data.snf.ch/grants/grant/152495)

The [SCOPES](http://www.snf.ch/en/funding/programmes/scopes/Pages/default.aspx)
project on Speech Prosody was a collaboration with BME-TMIT in Budapest, FEEIT in Skopje and the RTD group at UNS in Novi Sad.

## [SIWIS](http://www.idiap.ch/project/siwis/)

Spoken Interaction with Interpretation in Switzerland was a [sinergia](http://www.snf.ch/en/funding/programmes/sinergia/Pages/default.aspx) project funded by [SNSF](http://www.snf.ch/).  At Idiap it funded Alexandros Lazaridis and Pierre-Edouard Honnet.

## armasuisse

This work was with Petr Motlicek and Milos Cernak for the [defence procurement](http://www.ar.admin.ch/internet/armasuisse/en/home.html) arm of
the Swiss government.  We aim to use the synthesis technology from EMIME to do
low bit rate coding.

## Samsung GRO

Working with Petr Motlicek and [Samsung's SAIT lab](http://www.sait.samsung.co.kr/) under the [GRO program](http://www.sait.samsung.co.kr/saithome/01_about/gro_overview.jsp) on
advanced multi-lingual acoustic modelling for speech recognition.  The
project continued, funded directly by SAIT.

## MediaParl

This was a project aiming to do speech recognition and indexing of the Valaisan
parliament.  It was run by Alexandre Nanchen; I helped where possible along
with György Szaszak.

## V-FAST

Another [Hasler Foundation](http://www.haslerstiftung.ch/en/home) project
related to CLAS3, but focussed on fast adaptation using vocal tract
normalisation methods developed by Lakshmi Saheer.

## CLAS3

This was a [Hasler Foundation](http://www.haslerstiftung.ch/en/home) funded
project allowing Hui Liang to finish his PhD work.  The cross lingual
adaptation techniques that Hui developed are the basis for SIWIS.

## [EMIME](http://www.emime.org/)

I worked on EMIME with John Dines, Lakshmi Saheer and Hui Liang.  That project continued in a Swiss sense as SIWIS.

## [AMIDA](http://www.amiproject.org/)

I worked on AMIDA until it finished at the end of 2009. That work continued under [IM2](http://www.im2.ch/). It was closely related to the [TA2](http://www.ta2-project.eu/) project.

